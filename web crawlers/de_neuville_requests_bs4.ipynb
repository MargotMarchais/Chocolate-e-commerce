{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2989793c",
   "metadata": {},
   "source": [
    "<div style=\" background-color: RGB(0,114,200);\" >\n",
    "<h1 style=\"margin: auto; padding: 20px 0; color:#fff; text-align: center\">CHOCOLATE PROJECT</h1>\n",
    "<h2 style=\"margin: auto; padding: 20px 0; color:#fff; text-align: center\">Create the Leonidas dataset\n",
    "</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c4ae3",
   "metadata": {},
   "source": [
    "Note: I was able to perform this web scraping code thanks to the Youtube tutorial made by Darshil Parmar (https://www.youtube.com/watch?v=2hPCX-p_X8Q&t=71s&ab_channel=DarshilParmar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad003fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eea2f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions that will be used for performing web scraping\n",
    "\n",
    "# Function to extract Product name\n",
    "def get_product_name(soup):\n",
    "    \n",
    "    try:\n",
    "        title = soup.find(\"h1\", attrs = {\"class\": \"product-name\"}).text.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "        title = \"\"\n",
    "        \n",
    "    return title\n",
    "\n",
    "\n",
    "# Function to extract Product Description\n",
    "def get_product_descr(soup):\n",
    "    \n",
    "    try: \n",
    "        description = soup.find(\"div\", attrs = {\"class\": \"wysiwyg\"}).find('p').text.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        description = \"\"\n",
    "        \n",
    "    return description\n",
    "\n",
    "\n",
    "# Function to extract Product Price\n",
    "def get_product_price(soup):\n",
    "    \n",
    "    try: \n",
    "        price = soup.find(\"span\", attrs = {\"class\": \"current-price\"}).text.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        price = \"\"\n",
    "        \n",
    "    return price\n",
    "\n",
    "\n",
    "# Function to extract Product Price per kg\n",
    "def get_product_price_per_kg(soup):\n",
    "    \n",
    "    try: \n",
    "        price_kg = soup.find(\"span\", attrs = {\"class\": \"price_euro_kilo\"}).text.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        price_kg = \"\"\n",
    "        \n",
    "    return price_kg\n",
    "\n",
    "\n",
    "# Function to extract Weight\n",
    "def get_product_weight(soup):\n",
    "    \n",
    "    try: \n",
    "        weight = soup.find(\"p\", attrs = {\"class\": \"current-weight-price\"}).find('span').text.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        weight = \"\"\n",
    "        \n",
    "    return weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f583dc",
   "metadata": {},
   "source": [
    "<div style=\"background-color: RGB(0,150,250);\" >\n",
    "<h2 style=\"margin: auto; padding: 20px; color:#fff; \">Web scraping in action</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1980c833",
   "metadata": {},
   "source": [
    "De Neuville website has several sections: \"Assortiments\", \"Tablettes et carrés\", \"Spécialités régionales\", \"Avec le café\", \"A grignoter\", \"Juste pour faire plaisir\". We develop one script per section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb145cc",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid RGB(0,150,250);\" >\n",
    "<h3 style=\"margin: auto; padding: 20px; color: RGB(0,150,250); \">1. Web scraping script: Chocolate bars</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad858bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'\n",
    "    \n",
    "    # Headers for request\n",
    "    headers = ({'User-Agent': agent})\n",
    "    \n",
    "    # Webpage URL\n",
    "    url = 'https://www.chocolat-deneuville.com/nos-produits/tablettes-carres/'\n",
    "    \n",
    "    # HTTP request\n",
    "    webpage = requests.get(url, headers = headers)\n",
    "    \n",
    "    # Soup object containing all the data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    \n",
    "    # Fetch links as List of Tag Objects\n",
    "    links = soup.find_all(\"a\", attrs= {'class' : \"product-img referal\"})\n",
    "    \n",
    "    # Store the links\n",
    "    links_list = []\n",
    "    \n",
    "    # Loop for extracting links from Tag Object\n",
    "    for link in links:\n",
    "        links_list.append(link.get('href'))\n",
    "        \n",
    "    d = {'product_name' : [],\n",
    "        'product_description' : [],\n",
    "        'product_price': [],\n",
    "        'product_price_kg': [],\n",
    "         'product_weight': []\n",
    "        }\n",
    "    \n",
    "    # Loop for extracting product details from each link\n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get(link, headers = headers)\n",
    "        new_soup = BeautifulSoup(new_webpage.content, 'html.parser')\n",
    "        \n",
    "        # Function calls to display all necessary product information\n",
    "        d[\"product_name\"].append(get_product_name(new_soup))\n",
    "        d[\"product_description\"].append(get_product_descr(new_soup))\n",
    "        d[\"product_price\"].append(get_product_price(new_soup))\n",
    "        d['product_price_kg'].append(get_product_price_per_kg(new_soup)),\n",
    "        d['product_weight'].append(get_product_weight(new_soup))\n",
    "        \n",
    "    tablettes_df = pd.DataFrame.from_dict(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44a54d",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid RGB(0,150,250);\" >\n",
    "<h3 style=\"margin: auto; padding: 20px; color: RGB(0,150,250); \">2. Web scraping script: Assortiments</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302c2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'\n",
    "    \n",
    "    # Headers for request\n",
    "    headers = ({'User-Agent': agent})\n",
    "    \n",
    "    # Webpage URL\n",
    "    url = 'https://www.chocolat-deneuville.com/nos-produits/assortiments/'\n",
    "    \n",
    "    # HTTP request\n",
    "    webpage = requests.get(url, headers = headers)\n",
    "    \n",
    "    # Soup object containing all the data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    \n",
    "    # Fetch links as List of Tag Objects\n",
    "    links = soup.find_all(\"a\", attrs= {'class' : \"product-img referal\"})\n",
    "    \n",
    "    # Store the links\n",
    "    links_list = []\n",
    "    \n",
    "    # Loop for extracting links from Tag Object\n",
    "    for link in links:\n",
    "        links_list.append(link.get('href'))\n",
    "        \n",
    "    d = {'product_name' : [],\n",
    "        'product_description' : [],\n",
    "        'product_price': [],\n",
    "        'product_price_kg': [],\n",
    "         'product_weight': []\n",
    "        }\n",
    "    \n",
    "    # Loop for extracting product details from each link\n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get(link, headers = headers)\n",
    "        new_soup = BeautifulSoup(new_webpage.content, 'html.parser')\n",
    "        \n",
    "        # Function calls to display all necessary product information\n",
    "        d[\"product_name\"].append(get_product_name(new_soup))\n",
    "        d[\"product_description\"].append(get_product_descr(new_soup))\n",
    "        d[\"product_price\"].append(get_product_price(new_soup))\n",
    "        d['product_price_kg'].append(get_product_price_per_kg(new_soup)),\n",
    "        d['product_weight'].append(get_product_weight(new_soup))\n",
    "        \n",
    "    assortiments_df = pd.DataFrame.from_dict(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77c31e",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid RGB(0,150,250);\" >\n",
    "<h3 style=\"margin: auto; padding: 20px; color: RGB(0,150,250); \">3. Web scraping script: Regional Specialties</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe60eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'\n",
    "    \n",
    "    # Headers for request\n",
    "    headers = ({'User-Agent': agent})\n",
    "    \n",
    "    # Webpage URL\n",
    "    url = 'https://www.chocolat-deneuville.com/nos-produits/specialites-regionales/'\n",
    "    \n",
    "    # HTTP request\n",
    "    webpage = requests.get(url, headers = headers)\n",
    "    \n",
    "    # Soup object containing all the data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    \n",
    "    # Fetch links as List of Tag Objects\n",
    "    links = soup.find_all(\"a\", attrs= {'class' : \"product-img referal\"})\n",
    "    \n",
    "    # Store the links\n",
    "    links_list = []\n",
    "    \n",
    "    # Loop for extracting links from Tag Object\n",
    "    for link in links:\n",
    "        links_list.append(link.get('href'))\n",
    "        \n",
    "    d = {'product_name' : [],\n",
    "        'product_description' : [],\n",
    "        'product_price': [],\n",
    "        'product_price_kg': [],\n",
    "         'product_weight': []\n",
    "        }\n",
    "    \n",
    "    # Loop for extracting product details from each link\n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get(link, headers = headers)\n",
    "        new_soup = BeautifulSoup(new_webpage.content, 'html.parser')\n",
    "        \n",
    "        # Function calls to display all necessary product information\n",
    "        d[\"product_name\"].append(get_product_name(new_soup))\n",
    "        d[\"product_description\"].append(get_product_descr(new_soup))\n",
    "        d[\"product_price\"].append(get_product_price(new_soup))\n",
    "        d['product_price_kg'].append(get_product_price_per_kg(new_soup)),\n",
    "        d['product_weight'].append(get_product_weight(new_soup))\n",
    "        \n",
    "    reg_special_df = pd.DataFrame.from_dict(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add967d4",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid RGB(0,150,250);\" >\n",
    "<h3 style=\"margin: auto; padding: 20px; color: RGB(0,150,250); \">4. Web scraping script: With coffee</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa32efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'\n",
    "    \n",
    "    # Headers for request\n",
    "    headers = ({'User-Agent': agent})\n",
    "    \n",
    "    # Webpage URL\n",
    "    url = 'https://www.chocolat-deneuville.com/nos-produits/avec-le-cafe/'\n",
    "    \n",
    "    # HTTP request\n",
    "    webpage = requests.get(url, headers = headers)\n",
    "    \n",
    "    # Soup object containing all the data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    \n",
    "    # Fetch links as List of Tag Objects\n",
    "    links = soup.find_all(\"a\", attrs= {'class' : \"product-img referal\"})\n",
    "    \n",
    "    # Store the links\n",
    "    links_list = []\n",
    "    \n",
    "    # Loop for extracting links from Tag Object\n",
    "    for link in links:\n",
    "        links_list.append(link.get('href'))\n",
    "        \n",
    "    d = {'product_name' : [],\n",
    "        'product_description' : [],\n",
    "        'product_price': [],\n",
    "        'product_price_kg': [],\n",
    "         'product_weight': []\n",
    "        }\n",
    "    \n",
    "    # Loop for extracting product details from each link\n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get(link, headers = headers)\n",
    "        new_soup = BeautifulSoup(new_webpage.content, 'html.parser')\n",
    "        \n",
    "        # Function calls to display all necessary product information\n",
    "        d[\"product_name\"].append(get_product_name(new_soup))\n",
    "        d[\"product_description\"].append(get_product_descr(new_soup))\n",
    "        d[\"product_price\"].append(get_product_price(new_soup))\n",
    "        d['product_price_kg'].append(get_product_price_per_kg(new_soup)),\n",
    "        d['product_weight'].append(get_product_weight(new_soup))\n",
    "        \n",
    "    with_coffee_df = pd.DataFrame.from_dict(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebce977",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid RGB(0,150,250);\" >\n",
    "<h3 style=\"margin: auto; padding: 20px; color: RGB(0,150,250); \">5. Web scraping script: Snacking</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "278c56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'\n",
    "    \n",
    "    # Headers for request\n",
    "    headers = ({'User-Agent': agent})\n",
    "    \n",
    "    # Webpage URL\n",
    "    url = 'https://www.chocolat-deneuville.com/nos-produits/a-grignoter/'\n",
    "    \n",
    "    # HTTP request\n",
    "    webpage = requests.get(url, headers = headers)\n",
    "    \n",
    "    # Soup object containing all the data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    \n",
    "    # Fetch links as List of Tag Objects\n",
    "    links = soup.find_all(\"a\", attrs= {'class' : \"product-img referal\"})\n",
    "    \n",
    "    # Store the links\n",
    "    links_list = []\n",
    "    \n",
    "    # Loop for extracting links from Tag Object\n",
    "    for link in links:\n",
    "        links_list.append(link.get('href'))\n",
    "        \n",
    "    d = {'product_name' : [],\n",
    "        'product_description' : [],\n",
    "        'product_price': [],\n",
    "        'product_price_kg': [],\n",
    "         'product_weight': []\n",
    "        }\n",
    "    \n",
    "    # Loop for extracting product details from each link\n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get(link, headers = headers)\n",
    "        new_soup = BeautifulSoup(new_webpage.content, 'html.parser')\n",
    "        \n",
    "        # Function calls to display all necessary product information\n",
    "        d[\"product_name\"].append(get_product_name(new_soup))\n",
    "        d[\"product_description\"].append(get_product_descr(new_soup))\n",
    "        d[\"product_price\"].append(get_product_price(new_soup))\n",
    "        d['product_price_kg'].append(get_product_price_per_kg(new_soup)),\n",
    "        d['product_weight'].append(get_product_weight(new_soup))\n",
    "        \n",
    "    snacking_df = pd.DataFrame.from_dict(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa0fb13",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid RGB(0,150,250);\" >\n",
    "<h3 style=\"margin: auto; padding: 20px; color: RGB(0,150,250); \">6. Web scraping script: Gifts</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf378433",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'\n",
    "    \n",
    "    # Headers for request\n",
    "    headers = ({'User-Agent': agent})\n",
    "    \n",
    "    # Webpage URL\n",
    "    url = 'https://www.chocolat-deneuville.com/nos-produits/juste-pour-faire-plaisir/'\n",
    "    \n",
    "    # HTTP request\n",
    "    webpage = requests.get(url, headers = headers)\n",
    "    \n",
    "    # Soup object containing all the data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    \n",
    "    # Fetch links as List of Tag Objects\n",
    "    links = soup.find_all(\"a\", attrs= {'class' : \"product-img referal\"})\n",
    "    \n",
    "    # Store the links\n",
    "    links_list = []\n",
    "    \n",
    "    # Loop for extracting links from Tag Object\n",
    "    for link in links:\n",
    "        links_list.append(link.get('href'))\n",
    "        \n",
    "    d = {'product_name' : [],\n",
    "        'product_description' : [],\n",
    "        'product_price': [],\n",
    "        'product_price_kg': [],\n",
    "         'product_weight': []\n",
    "        }\n",
    "    \n",
    "    # Loop for extracting product details from each link\n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get(link, headers = headers)\n",
    "        new_soup = BeautifulSoup(new_webpage.content, 'html.parser')\n",
    "        \n",
    "        # Function calls to display all necessary product information\n",
    "        d[\"product_name\"].append(get_product_name(new_soup))\n",
    "        d[\"product_description\"].append(get_product_descr(new_soup))\n",
    "        d[\"product_price\"].append(get_product_price(new_soup))\n",
    "        d['product_price_kg'].append(get_product_price_per_kg(new_soup)),\n",
    "        d['product_weight'].append(get_product_weight(new_soup))\n",
    "        \n",
    "    gifts_df = pd.DataFrame.from_dict(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253f7e2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: RGB(0,150,250);\" >\n",
    "<h2 style=\"margin: auto; padding: 20px; color:#fff; \">Final dataset</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c32e8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deneuville_df = pd.concat([tablettes_df, assortiments_df, reg_special_df, with_coffee_df, snacking_df, gifts_df])\n",
    "deneuville_df['timestamp_photo'] = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff390ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 136 entries, 0 to 22\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   product_name         136 non-null    object        \n",
      " 1   product_description  136 non-null    object        \n",
      " 2   product_price        136 non-null    object        \n",
      " 3   product_price_kg     136 non-null    object        \n",
      " 4   product_weight       136 non-null    object        \n",
      " 5   timestamp_photo      136 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 7.4+ KB\n"
     ]
    }
   ],
   "source": [
    "deneuville_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b68debb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_price_kg</th>\n",
       "      <th>product_weight</th>\n",
       "      <th>timestamp_photo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tablette Bio cacao 100% Pérou</td>\n",
       "      <td>Découvrez notre tablette pure origine Pérou 10...</td>\n",
       "      <td>5,40 €</td>\n",
       "      <td>(63,52 €/kg)</td>\n",
       "      <td>Poids 85g</td>\n",
       "      <td>2024-06-08 20:58:26.558305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tablette Bio noir 88% République Dominicaine</td>\n",
       "      <td>Découvrez notre tablette pure origine Républiq...</td>\n",
       "      <td>5,40 €</td>\n",
       "      <td>(63,52 €/kg)</td>\n",
       "      <td>Poids 85g</td>\n",
       "      <td>2024-06-08 20:58:26.558305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tablette Bio noir 85% Pérou</td>\n",
       "      <td>Découvrez notre tablette pure origine Pérou, u...</td>\n",
       "      <td>5,40 €</td>\n",
       "      <td>(63,52 €/kg)</td>\n",
       "      <td>Poids 85g</td>\n",
       "      <td>2024-06-08 20:58:26.558305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tablette Bio lait 50% Madagascar</td>\n",
       "      <td>Découvrez notre tablette pure origine Madagasc...</td>\n",
       "      <td>5,40 €</td>\n",
       "      <td>(63,53 €/kg)</td>\n",
       "      <td>Poids 85g</td>\n",
       "      <td>2024-06-08 20:58:26.558305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tablette Bio noir 74% Madagascar</td>\n",
       "      <td>Découvrez notre tablette pure origine Madagasc...</td>\n",
       "      <td>5,40 €</td>\n",
       "      <td>(63,52 €/kg)</td>\n",
       "      <td>Poids 85g</td>\n",
       "      <td>2024-06-08 20:58:26.558305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   product_name  \\\n",
       "0                 Tablette Bio cacao 100% Pérou   \n",
       "1  Tablette Bio noir 88% République Dominicaine   \n",
       "2                   Tablette Bio noir 85% Pérou   \n",
       "3              Tablette Bio lait 50% Madagascar   \n",
       "4              Tablette Bio noir 74% Madagascar   \n",
       "\n",
       "                                 product_description product_price  \\\n",
       "0  Découvrez notre tablette pure origine Pérou 10...        5,40 €   \n",
       "1  Découvrez notre tablette pure origine Républiq...        5,40 €   \n",
       "2  Découvrez notre tablette pure origine Pérou, u...        5,40 €   \n",
       "3  Découvrez notre tablette pure origine Madagasc...        5,40 €   \n",
       "4  Découvrez notre tablette pure origine Madagasc...        5,40 €   \n",
       "\n",
       "  product_price_kg product_weight            timestamp_photo  \n",
       "0     (63,52 €/kg)      Poids 85g 2024-06-08 20:58:26.558305  \n",
       "1     (63,52 €/kg)      Poids 85g 2024-06-08 20:58:26.558305  \n",
       "2     (63,52 €/kg)      Poids 85g 2024-06-08 20:58:26.558305  \n",
       "3     (63,53 €/kg)      Poids 85g 2024-06-08 20:58:26.558305  \n",
       "4     (63,52 €/kg)      Poids 85g 2024-06-08 20:58:26.558305  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deneuville_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ad32f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deneuville_df\n",
    "deneuville_df.to_csv(\"C:/Users/margo/Documents/Documents/Formation/Github/Web_scraping/chocolats/deneuville_df.csv\", \n",
    "                   header = True,\n",
    "                   index = False\n",
    "                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
